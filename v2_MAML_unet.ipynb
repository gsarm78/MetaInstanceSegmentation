{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('nga_dataset': conda)",
   "metadata": {
    "interpreter": {
     "hash": "bb9e3f02d6c4d05100e7b21625091cb1b2e20dc347bced82cea7272b14bb03ea"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dataloader import *\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d =  DataGenerator(dataset_csv='/home/mendeza/Documents/dataset_10_31_2020_3903_clustered.csv',\n",
    "                   pano_directory='/home/mendeza/Documents/data2/pano_image',\n",
    "                   label_directory='/home/mendeza/Documents/data2/labels',\n",
    "                   num_classes=1,\n",
    "                   num_samples_per_class=2*2,\n",
    "                   num_meta_test_classes=1,\n",
    "                   num_meta_test_samples_per_class=3*2,#3-shot test\n",
    "                   IMG_WIDTH=256,\n",
    "                   IMG_HEIGHT=256,\n",
    "                   num_circles=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(16, 1, 4, 256, 256, 3)\n(16, 1, 4, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "images,labels = d.sample_batch('meta_train',16)\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4, 256, 256, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "images[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    }
   ],
   "source": [
    "from segmentation_models import Unet\n",
    "import segmentation_models as sm\n",
    "from segmentation_models import get_preprocessing\n",
    "from segmentation_models.losses import bce_jaccard_loss\n",
    "# from segmentation_models.losses import bce_dice_loss\n",
    "from segmentation_models.metrics import iou_score\n",
    "\n",
    "\n",
    "BACKBONE='mobilenet'\n",
    "preprocess_input = get_preprocessing(BACKBONE)\n",
    "# model = Unet(BACKBONE, encoder_weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.m.layers[2].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(img_rows,img_cols):\n",
    "    inputs = tf.keras.layers.Input((img_rows, img_cols, 3))\n",
    "    conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = tf.keras.layers.concatenate([tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = tf.keras.layers.concatenate([tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = tf.keras.layers.concatenate([tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 =tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 =tf.keras.layers.concatenate([tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 =tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 =tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 =tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    # model.compile(optimizer=tfAdam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in model.trainable_weights:\n",
    "#     print(layer.name,layer.shape)\n",
    "    # print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9761a98df63e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# for layer in model.trainable_weights:\n",
    "#     print(layer.name,layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.m.layers[2].weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models import Unet\n",
    "import segmentation_models as sm\n",
    "from segmentation_models import get_preprocessing\n",
    "from segmentation_models.losses import bce_jaccard_loss\n",
    "# from segmentation_models.losses import bce_dice_loss\n",
    "from segmentation_models.metrics import iou_score\n",
    "preprocess_input = get_preprocessing('mobilenet')\n",
    "from functools import partial\n",
    "\n",
    "def copy_model_fn(model):\n",
    "    copied_model = get_unet(224,224)\n",
    "    copied_model.set_weights(model.get_weights())\n",
    "    return copied_model\n",
    "\n",
    "class MAML_UNet(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 model_weights,\n",
    "                 dim_input=1,\n",
    "                 dim_output=1,\n",
    "                 num_inner_updates=1,\n",
    "                 inner_update_lr=0.4,\n",
    "                 k_shot=5,\n",
    "                 backbone='mobilenet',\n",
    "                 pretrain=False):\n",
    "        '''\n",
    "        '''\n",
    "        super(tf.keras.Model, self).__init__()\n",
    "        self.dim_input = dim_input\n",
    "        self.dim_output = dim_output\n",
    "        self.inner_update_lr = inner_update_lr\n",
    "        self.get_preprocessing = get_preprocessing\n",
    "        self.iou_score = iou_score\n",
    "        self.BACKBONE = backbone\n",
    "        self.pretrain = pretrain\n",
    "        self.loss_func = bce_jaccard_loss\n",
    "        self.preprocess_input = get_preprocessing(self.BACKBONE)\n",
    "        if self.pretrain:\n",
    "            self.m = get_unet(224,224)\n",
    "        else:\n",
    "            self.m = get_unet(224,224)\n",
    "\n",
    "\n",
    "        # outputs_ts[i] and losses_ts_post[i] are the output and loss after i+1 inner gradient updates\n",
    "        losses_tr_pre, outputs_tr, losses_ts_post, outputs_ts = [], [], [], []\n",
    "        accuracies_tr_pre, accuracies_ts = [], []\n",
    "\n",
    "        # for each loop in the inner training loop\n",
    "        outputs_ts = [[]]*num_inner_updates\n",
    "        losses_ts_post = [[]]*num_inner_updates\n",
    "        accuracies_ts = [[]]*num_inner_updates\n",
    "\n",
    "        self.w = self.m.trainable_weights\n",
    "    # @tf.function\n",
    "    def call(self,\n",
    "             inp,\n",
    "             meta_batch_size=25,\n",
    "             num_inner_updates=1):\n",
    "        def task_inner_loop(inp,reuse=True,meta_batch_size=25,num_inner_updates=1):\n",
    "            '''\n",
    "            '''\n",
    "            # the inner and outer loop data\n",
    "            # query set: (input_tr,label_tr)\n",
    "            input_tr, input_ts, label_tr, label_ts = inp\n",
    "\n",
    "            # weights corresponds to the initial weights in MAML (i.e. the meta-parameters)\n",
    "            weights = self.w\n",
    "\n",
    "            # the predicted outputs, loss values, and accuracy for the pre-update model (with the initial weights)\n",
    "            # evaluated on the inner loop training data\n",
    "            task_output_tr_pre, task_loss_tr_pre, task_accuracy_tr_pre = None, None, None\n",
    "\n",
    "            # lists to keep track of outputs, losses, and accuracies of test data for each inner_update\n",
    "            # where task_outputs_ts[i], task_losses_ts[i], task_accuracies_ts[i] are the output, loss, and accuracy\n",
    "            # after i+1 inner gradient updates\n",
    "            task_outputs_ts, task_losses_ts, task_accuracies_ts = [], [], []\n",
    "            # model = Unet(self.BACKBONE, encoder_weights=None)\n",
    "            # for i in range(len(model.trainable_weights)):\n",
    "            #     model.trainable_weights[i].assign(weights[i])\n",
    "                \n",
    "            # model = copy_model_fn(self.m,input_tr) \n",
    "            # model(input_tr)\n",
    "            # copy_model(input_tr)\n",
    "            ######################################\n",
    "            ############### MAML #################\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                # print(input_tr.shape)\n",
    "                # tape.watch(model.trainable_weights)\n",
    "                copied_model = copy_model_fn(model)\n",
    "                task_output_tr_pre = copy_model_fn(input_tr)# logits\n",
    "                task_loss_tr_pre = self.loss_func(label_tr,task_output_tr_pre)\n",
    "\n",
    "                k=0\n",
    "                for j in range(len(model.layers)):\n",
    "                    # print(j,m.layers[j].name,copied_model.layers[j].name)\n",
    "                    \n",
    "                    if j not in [0,3,6,9,12,16,20,24,28]:\n",
    "                        # print(j,copied_model.layers[j].name)\n",
    "                        # print(j,k,copied_model.layers[j].kernel.shape,m.layers[j].kernel.shape,grads[k].shape)\n",
    "                        # print(j,k+1,copied_model.layers[j].bias.shape,m.layers[j].bias.shape,grads[k+1].shape)\n",
    "                        # print(j,copied_model.layers[j].bias.name,copied_model.layers[j].bias.shape)\n",
    "                        # print(j,copied_model.layers[j].kernel.name,m.layers[j].kernel.shape)\n",
    "                        # print(grads[k].shape)\n",
    "                        copied_model.layers[j].kernel = m.layers[j].kernel - self.inner_learn_rate*grads[k]\n",
    "                        copied_model.layers[j].bias = m.layers[j].bias - self.inner_learn_rate*grads[k+1]\n",
    "                        k+=2\n",
    "\n",
    "                output_ts = copy_model(input_ts,training=True)\n",
    "                loss_ts = self.loss_func(label_ts,output_ts)\n",
    "\n",
    "                task_outputs_ts.append(output_ts)\n",
    "                # print(\"task_outputs_ts {}\".format(task_outputs_ts))#(B,5)\n",
    "                task_losses_ts.append(loss_ts)\n",
    "                if num_inner_updates > 1:\n",
    "                    # model.set_weights(fast_weights)\n",
    "                    for update in range(num_inner_updates-1):\n",
    "                        outputt = copy_model(input_tr,training=True)\n",
    "                        losss = self.loss_func(label_tr,outputt)\n",
    "                        grads = tape.gradient(losss,copy_model.trainable_weights)\n",
    "\n",
    "                        for j in range(len(model.trainable_weights)):\n",
    "                            copy_model.trainable_weights[j] = copy_model.trainable_weights[j] - self.inner_update_lr*grads[j]\n",
    "                        \n",
    "                        outputtt = copy_model(input_ts,training=True)\n",
    "                        task_outputs_ts.append(outputtt)\n",
    "                        task_losses_ts.append(self.loss_func(label_ts,outputtt))\n",
    "            # Compute accuracies from output predictions\n",
    "            task_accuracy_tr_pre = self.iou_score(label_tr,task_output_tr_pre)\n",
    "\n",
    "            for j in range(num_inner_updates):\n",
    "                task_accuracies_ts.append(self.iou_score(label_ts,task_outputs_ts[j]))\n",
    "\n",
    "            task_output = [task_output_tr_pre, task_outputs_ts, task_loss_tr_pre, task_losses_ts, task_accuracy_tr_pre, task_accuracies_ts]\n",
    "\n",
    "            return task_output\n",
    "\n",
    "        out_dtype = [tf.float32, [tf.float32]*num_inner_updates, tf.float32, [tf.float32]*num_inner_updates]\n",
    "        out_dtype.extend([tf.float32, [tf.float32]*num_inner_updates])\n",
    "        task_inner_loop_partial = partial(task_inner_loop, meta_batch_size=meta_batch_size, num_inner_updates=num_inner_updates)\n",
    "        result = tf.map_fn(task_inner_loop_partial,\n",
    "                        elems=(input_tr, input_ts, label_tr, label_ts),\n",
    "                        dtype=out_dtype,\n",
    "                        parallel_iterations=meta_batch_size)\n",
    "        return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " model = MAML_UNet(None,\n",
    "                 dim_input=1,\n",
    "                 dim_output=1,\n",
    "                 num_inner_updates=1,\n",
    "                 inner_update_lr=0.4,\n",
    "                 k_shot=5,\n",
    "                 backbone='mobilenet',\n",
    "                 pretrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8 1 4 256 256 3\nimages: (8, 4, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# images,\n",
    "k_shot=2\n",
    "images,labels = d.sample_batch('meta_train',8)\n",
    "b,n,k,w,h,c = images.shape\n",
    "print(b,n,k,w,h,c)\n",
    "images = images.reshape((b,n*k,w,h,c))\n",
    "print(\"images: {}\".format(images.shape))\n",
    "labels = labels.reshape((b,n*k,w,h,1))\n",
    "\n",
    "input_tr  = images[:,:k_shot]\n",
    "label_tr = labels[:,:k_shot]\n",
    "input_ts = images[:,k_shot:]\n",
    "label_ts = labels[:,k_shot:]\n",
    "\n",
    "input_tr = preprocess_input(input_tr)\n",
    "input_tr = tf.convert_to_tensor(input_tr,tf.float32)\n",
    "input_ts = preprocess_input(input_ts)\n",
    "input_ts = tf.convert_to_tensor(input_ts,tf.float32)\n",
    "\n",
    "label_tr = tf.convert_to_tensor(label_tr,tf.float32)\n",
    "label_ts = tf.convert_to_tensor(label_ts,tf.float32)\n",
    "inp = (input_tr, input_ts, label_tr, label_ts)\n",
    "# result = model(inp, meta_batch_size=16, num_inner_updates=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.m.trainable_variables\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def outer_train_step(inp, model, optim, meta_batch_size=25, num_inner_updates=1):\n",
    "  # note here, outer tape constructed to watch all model.trainable_variables!\n",
    "  # inner_loop is called in model(...)\n",
    "  # no need to do persistent, since only 1 outer_tape.gradient needs to be called\n",
    "  with tf.GradientTape(persistent=False) as outer_tape:\n",
    "    result = model(inp, meta_batch_size=meta_batch_size, num_inner_updates=num_inner_updates)\n",
    "\n",
    "    outputs_tr, outputs_ts, losses_tr_pre, losses_ts, accuracies_tr_pre, accuracies_ts = result\n",
    "\n",
    "    total_losses_ts = [tf.reduce_mean(loss_ts) for loss_ts in losses_ts]\n",
    "  # dont need to update self.inner_update_lr_dict,\n",
    "  # since learn rate is part of the model.training_variables\n",
    "  gradients = outer_tape.gradient(total_losses_ts[-1], model.m.trainable_weights)\n",
    "  # this will update ALL PARAMETERS, including the LEARN RATE!\n",
    "  # rather than manual gradient descent, Adam (adaptive grad descent) used to update params\n",
    "  optim.apply_gradients(zip(gradients, model.m.trainable_weights))\n",
    "\n",
    "  total_loss_tr_pre = tf.reduce_mean(losses_tr_pre)\n",
    "  total_accuracy_tr_pre = tf.reduce_mean(accuracies_tr_pre)\n",
    "  total_accuracies_ts = [tf.reduce_mean(accuracy_ts) for accuracy_ts in accuracies_ts]\n",
    "\n",
    "  return outputs_tr, outputs_ts, total_loss_tr_pre, total_losses_ts, total_accuracy_tr_pre, total_accuracies_ts\n",
    "\n",
    "def outer_eval_step(inp, model, meta_batch_size=25, num_inner_updates=1):\n",
    "  result = model(inp, meta_batch_size=meta_batch_size, num_inner_updates=num_inner_updates)\n",
    "\n",
    "  outputs_tr, outputs_ts, losses_tr_pre, losses_ts, accuracies_tr_pre, accuracies_ts = result\n",
    "\n",
    "  total_loss_tr_pre = tf.reduce_mean(losses_tr_pre)\n",
    "  total_losses_ts = [tf.reduce_mean(loss_ts) for loss_ts in losses_ts]\n",
    "\n",
    "  total_accuracy_tr_pre = tf.reduce_mean(accuracies_tr_pre)\n",
    "  total_accuracies_ts = [tf.reduce_mean(accuracy_ts) for accuracy_ts in accuracies_ts]\n",
    "\n",
    "  return outputs_tr, outputs_ts, total_loss_tr_pre, total_losses_ts, total_accuracy_tr_pre, total_accuracies_ts\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "# t0 = time()\n",
    "# result = outer_train_step(inp, model, optimizer, meta_batch_size=8, num_inner_updates=1)\n",
    "# print(\"Time: {}\".format(time()-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]8 1 4 256 256 3\n",
      "images: (8, 4, 256, 256, 3)\n",
      "WARNING:tensorflow:Setting parallel_iterations > 1 has no effect when executing eagerly. Consider calling map_fn with tf.contrib.eager.defun to execute fn in parallel.\n",
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n",
      "  0%|          | 0/3 [00:28<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: ['conv1_1/kernel:0', 'conv1_bn_1/gamma:0', 'conv1_bn_1/beta:0', 'conv_dw_1_1/depthwise_kernel:0', 'conv_dw_1_bn_1/gamma:0', 'conv_dw_1_bn_1/beta:0', 'conv_pw_1_1/kernel:0', 'conv_pw_1_bn_1/gamma:0', 'conv_pw_1_bn_1/beta:0', 'conv_dw_2_1/depthwise_kernel:0', 'conv_dw_2_bn_1/gamma:0', 'conv_dw_2_bn_1/beta:0', 'conv_pw_2_1/kernel:0', 'conv_pw_2_bn_1/gamma:0', 'conv_pw_2_bn_1/beta:0', 'conv_dw_3_1/depthwise_kernel:0', 'conv_dw_3_bn_1/gamma:0', 'conv_dw_3_bn_1/beta:0', 'conv_pw_3_1/kernel:0', 'conv_pw_3_bn_1/gamma:0', 'conv_pw_3_bn_1/beta:0', 'conv_dw_4_1/depthwise_kernel:0', 'conv_dw_4_bn_1/gamma:0', 'conv_dw_4_bn_1/beta:0', 'conv_pw_4_1/kernel:0', 'conv_pw_4_bn_1/gamma:0', 'conv_pw_4_bn_1/beta:0', 'conv_dw_5_1/depthwise_kernel:0', 'conv_dw_5_bn_1/gamma:0', 'conv_dw_5_bn_1/beta:0', 'conv_pw_5_1/kernel:0', 'conv_pw_5_bn_1/gamma:0', 'conv_pw_5_bn_1/beta:0', 'conv_dw_6_1/depthwise_kernel:0', 'conv_dw_6_bn_1/gamma:0', 'conv_dw_6_bn_1/beta:0', 'conv_pw_6_1/kernel:0', 'conv_pw_6_bn_1/gamma:0', 'conv_pw_6_bn_1/beta:0', 'conv_dw_7_1/depthwise_kernel:0', 'conv_dw_7_bn_1/gamma:0', 'conv_dw_7_bn_1/beta:0', 'conv_pw_7_1/kernel:0', 'conv_pw_7_bn_1/gamma:0', 'conv_pw_7_bn_1/beta:0', 'conv_dw_8_1/depthwise_kernel:0', 'conv_dw_8_bn_1/gamma:0', 'conv_dw_8_bn_1/beta:0', 'conv_pw_8_1/kernel:0', 'conv_pw_8_bn_1/gamma:0', 'conv_pw_8_bn_1/beta:0', 'conv_dw_9_1/depthwise_kernel:0', 'conv_dw_9_bn_1/gamma:0', 'conv_dw_9_bn_1/beta:0', 'conv_pw_9_1/kernel:0', 'conv_pw_9_bn_1/gamma:0', 'conv_pw_9_bn_1/beta:0', 'conv_dw_10_1/depthwise_kernel:0', 'conv_dw_10_bn_1/gamma:0', 'conv_dw_10_bn_1/beta:0', 'conv_pw_10_1/kernel:0', 'conv_pw_10_bn_1/gamma:0', 'conv_pw_10_bn_1/beta:0', 'conv_dw_11_1/depthwise_kernel:0', 'conv_dw_11_bn_1/gamma:0', 'conv_dw_11_bn_1/beta:0', 'conv_pw_11_1/kernel:0', 'conv_pw_11_bn_1/gamma:0', 'conv_pw_11_bn_1/beta:0', 'conv_dw_12_1/depthwise_kernel:0', 'conv_dw_12_bn_1/gamma:0', 'conv_dw_12_bn_1/beta:0', 'conv_pw_12_1/kernel:0', 'conv_pw_12_bn_1/gamma:0', 'conv_pw_12_bn_1/beta:0', 'conv_dw_13_1/depthwise_kernel:0', 'conv_dw_13_bn_1/gamma:0', 'conv_dw_13_bn_1/beta:0', 'conv_pw_13_1/kernel:0', 'conv_pw_13_bn_1/gamma:0', 'conv_pw_13_bn_1/beta:0', 'decoder_stage0a_conv_1/kernel:0', 'decoder_stage0a_bn_1/gamma:0', 'decoder_stage0a_bn_1/beta:0', 'decoder_stage0b_conv_1/kernel:0', 'decoder_stage0b_bn_1/gamma:0', 'decoder_stage0b_bn_1/beta:0', 'decoder_stage1a_conv_1/kernel:0', 'decoder_stage1a_bn_1/gamma:0', 'decoder_stage1a_bn_1/beta:0', 'decoder_stage1b_conv_1/kernel:0', 'decoder_stage1b_bn_1/gamma:0', 'decoder_stage1b_bn_1/beta:0', 'decoder_stage2a_conv_1/kernel:0', 'decoder_stage2a_bn_1/gamma:0', 'decoder_stage2a_bn_1/beta:0', 'decoder_stage2b_conv_1/kernel:0', 'decoder_stage2b_bn_1/gamma:0', 'decoder_stage2b_bn_1/beta:0', 'decoder_stage3a_conv_1/kernel:0', 'decoder_stage3a_bn_1/gamma:0', 'decoder_stage3a_bn_1/beta:0', 'decoder_stage3b_conv_1/kernel:0', 'decoder_stage3b_bn_1/gamma:0', 'decoder_stage3b_bn_1/beta:0', 'decoder_stage4a_conv_1/kernel:0', 'decoder_stage4a_bn_1/gamma:0', 'decoder_stage4a_bn_1/beta:0', 'decoder_stage4b_conv_1/kernel:0', 'decoder_stage4b_bn_1/gamma:0', 'decoder_stage4b_bn_1/beta:0', 'final_conv_1/kernel:0', 'final_conv_1/bias:0'].",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-770710ff52d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mouter_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inner_updates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_inner_updates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mitr\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mSUMMARY_INTERVAL\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0mpre_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-f97f64757786>\u001b[0m in \u001b[0;36mouter_train_step\u001b[0;34m(inp, model, optim, meta_batch_size, num_inner_updates)\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;31m# this will update ALL PARAMETERS, including the LEARN RATE!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;31m# rather than manual gradient descent, Adam (adaptive grad descent) used to update params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mtotal_loss_tr_pre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses_tr_pre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nga_dataset/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    425\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mnone\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \"\"\"\n\u001b[0;32m--> 427\u001b[0;31m     \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_filter_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nga_dataset/lib/python3.6/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_filter_grads\u001b[0;34m(grads_and_vars)\u001b[0m\n\u001b[1;32m   1023\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m     raise ValueError(\"No gradients provided for any variable: %s.\" %\n\u001b[0;32m-> 1025\u001b[0;31m                      ([v.name for _, v in grads_and_vars],))\n\u001b[0m\u001b[1;32m   1026\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     logging.warning(\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable: ['conv1_1/kernel:0', 'conv1_bn_1/gamma:0', 'conv1_bn_1/beta:0', 'conv_dw_1_1/depthwise_kernel:0', 'conv_dw_1_bn_1/gamma:0', 'conv_dw_1_bn_1/beta:0', 'conv_pw_1_1/kernel:0', 'conv_pw_1_bn_1/gamma:0', 'conv_pw_1_bn_1/beta:0', 'conv_dw_2_1/depthwise_kernel:0', 'conv_dw_2_bn_1/gamma:0', 'conv_dw_2_bn_1/beta:0', 'conv_pw_2_1/kernel:0', 'conv_pw_2_bn_1/gamma:0', 'conv_pw_2_bn_1/beta:0', 'conv_dw_3_1/depthwise_kernel:0', 'conv_dw_3_bn_1/gamma:0', 'conv_dw_3_bn_1/beta:0', 'conv_pw_3_1/kernel:0', 'conv_pw_3_bn_1/gamma:0', 'conv_pw_3_bn_1/beta:0', 'conv_dw_4_1/depthwise_kernel:0', 'conv_dw_4_bn_1/gamma:0', 'conv_dw_4_bn_1/beta:0', 'conv_pw_4_1/kernel:0', 'conv_pw_4_bn_1/gamma:0', 'conv_pw_4_bn_1/beta:0', 'conv_dw_5_1/depthwise_kernel:0', 'conv_dw_5_bn_1/gamma:0', 'conv_dw_5_bn_1/beta:0', 'conv_pw_5_1/kernel:0', 'conv_pw_5_bn_1/gamma:0', 'conv_pw_5_bn_1/beta:0', 'conv_dw_6_1/depthwise_kernel:0', 'conv_dw_6_bn_1/gamma:0', 'conv_dw_6_bn_1/beta:0', 'conv_pw_6_1/kernel:0', 'conv_pw_6_bn_1/gamma:0', 'conv_pw_6_bn_1/beta:0', 'conv_dw_7_1/depthwise_kernel:0', 'conv_dw_7_bn_1/gamma:0', 'conv_dw_7_bn_1/beta:0', 'conv_pw_7_1/kernel:0', 'conv_pw_7_bn_1/gamma:0', 'conv_pw_7_bn_1/beta:0', 'conv_dw_8_1/depthwise_kernel:0', 'conv_dw_8_bn_1/gamma:0', 'conv_dw_8_bn_1/beta:0', 'conv_pw_8_1/kernel:0', 'conv_pw_8_bn_1/gamma:0', 'conv_pw_8_bn_1/beta:0', 'conv_dw_9_1/depthwise_kernel:0', 'conv_dw_9_bn_1/gamma:0', 'conv_dw_9_bn_1/beta:0', 'conv_pw_9_1/kernel:0', 'conv_pw_9_bn_1/gamma:0', 'conv_pw_9_bn_1/beta:0', 'conv_dw_10_1/depthwise_kernel:0', 'conv_dw_10_bn_1/gamma:0', 'conv_dw_10_bn_1/beta:0', 'conv_pw_10_1/kernel:0', 'conv_pw_10_bn_1/gamma:0', 'conv_pw_10_bn_1/beta:0', 'conv_dw_11_1/depthwise_kernel:0', 'conv_dw_11_bn_1/gamma:0', 'conv_dw_11_bn_1/beta:0', 'conv_pw_11_1/kernel:0', 'conv_pw_11_bn_1/gamma:0', 'conv_pw_11_bn_1/beta:0', 'conv_dw_12_1/depthwise_kernel:0', 'conv_dw_12_bn_1/gamma:0', 'conv_dw_12_bn_1/beta:0', 'conv_pw_12_1/kernel:0', 'conv_pw_12_bn_1/gamma:0', 'conv_pw_12_bn_1/beta:0', 'conv_dw_13_1/depthwise_kernel:0', 'conv_dw_13_bn_1/gamma:0', 'conv_dw_13_bn_1/beta:0', 'conv_pw_13_1/kernel:0', 'conv_pw_13_bn_1/gamma:0', 'conv_pw_13_bn_1/beta:0', 'decoder_stage0a_conv_1/kernel:0', 'decoder_stage0a_bn_1/gamma:0', 'decoder_stage0a_bn_1/beta:0', 'decoder_stage0b_conv_1/kernel:0', 'decoder_stage0b_bn_1/gamma:0', 'decoder_stage0b_bn_1/beta:0', 'decoder_stage1a_conv_1/kernel:0', 'decoder_stage1a_bn_1/gamma:0', 'decoder_stage1a_bn_1/beta:0', 'decoder_stage1b_conv_1/kernel:0', 'decoder_stage1b_bn_1/gamma:0', 'decoder_stage1b_bn_1/beta:0', 'decoder_stage2a_conv_1/kernel:0', 'decoder_stage2a_bn_1/gamma:0', 'decoder_stage2a_bn_1/beta:0', 'decoder_stage2b_conv_1/kernel:0', 'decoder_stage2b_bn_1/gamma:0', 'decoder_stage2b_bn_1/beta:0', 'decoder_stage3a_conv_1/kernel:0', 'decoder_stage3a_bn_1/gamma:0', 'decoder_stage3a_bn_1/beta:0', 'decoder_stage3b_conv_1/kernel:0', 'decoder_stage3b_bn_1/gamma:0', 'decoder_stage3b_bn_1/beta:0', 'decoder_stage4a_conv_1/kernel:0', 'decoder_stage4a_bn_1/gamma:0', 'decoder_stage4a_bn_1/beta:0', 'decoder_stage4b_conv_1/kernel:0', 'decoder_stage4b_bn_1/gamma:0', 'decoder_stage4b_bn_1/beta:0', 'final_conv_1/kernel:0', 'final_conv_1/bias:0']."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "pre_accuracies, post_accuracies = [], []\n",
    "val_post_accs = []\n",
    "SUMMARY_INTERVAL = 1\n",
    "SAVE_INTERVAL = 1\n",
    "PRINT_INTERVAL = 1  \n",
    "# TEST_PRINT_INTERVAL = PRINT_INTERVAL*5\n",
    "TEST_PRINT_INTERVAL = 1\n",
    "\n",
    "batch_size = 8\n",
    "num_inner_updates = 1\n",
    "meta_train_iterations = 3\n",
    "for itr in tqdm(range(meta_train_iterations)):\n",
    "\n",
    "    k_shot=2\n",
    "    images,labels = d.sample_batch('meta_train',batch_size)\n",
    "    b,n,k,w,h,c = images.shape\n",
    "    print(b,n,k,w,h,c)\n",
    "    images = images.reshape((b,n*k,w,h,c))\n",
    "    print(\"images: {}\".format(images.shape))\n",
    "    labels = labels.reshape((b,n*k,w,h,1))\n",
    "\n",
    "    input_tr  = images[:,:k_shot]\n",
    "    label_tr = labels[:,:k_shot]\n",
    "    input_ts = images[:,k_shot:]\n",
    "    label_ts = labels[:,k_shot:]\n",
    "\n",
    "    input_tr = preprocess_input(input_tr)\n",
    "    input_tr = tf.convert_to_tensor(input_tr,tf.float32)\n",
    "    input_ts = preprocess_input(input_ts)\n",
    "    input_ts = tf.convert_to_tensor(input_ts,tf.float32)\n",
    "\n",
    "    label_tr = tf.convert_to_tensor(label_tr,tf.float32)\n",
    "    label_ts = tf.convert_to_tensor(label_ts,tf.float32)\n",
    "    inp = (input_tr, input_ts, label_tr, label_ts)\n",
    "\n",
    "    result = outer_train_step(inp, model, optimizer, meta_batch_size=batch_size, num_inner_updates=num_inner_updates)\n",
    "    if itr % SUMMARY_INTERVAL == 0:\n",
    "      pre_accuracies.append(result[-2])\n",
    "      post_accuracies.append(result[-1][-1])\n",
    "\n",
    "    if (itr!=0) and itr % PRINT_INTERVAL == 0:\n",
    "      print_str = 'Iteration %d: pre-inner-loop train accuracy: %.5f, post-inner-loop test accuracy: %.5f' % (itr, np.mean(pre_accuracies), np.mean(post_accuracies))\n",
    "      print(print_str)\n",
    "      # pre_accuracies, post_accuracies = [], []\n",
    "    if (itr!=0) and itr % TEST_PRINT_INTERVAL == 0:\n",
    "        k_shot=2\n",
    "        images,labels = d.sample_batch('meta_train',batch_size)\n",
    "        b,n,k,w,h,c = images.shape\n",
    "        print(b,n,k,w,h,c)\n",
    "        images = images.reshape((b,n*k,w,h,c))\n",
    "        print(\"images: {}\".format(images.shape))\n",
    "        labels = labels.reshape((b,n*k,w,h,1))\n",
    "\n",
    "        input_tr  = images[:,:k_shot]\n",
    "        label_tr = labels[:,:k_shot]\n",
    "        input_ts = images[:,k_shot:]\n",
    "        label_ts = labels[:,k_shot:]\n",
    "\n",
    "        input_tr = preprocess_input(input_tr)\n",
    "        input_tr = tf.convert_to_tensor(input_tr,tf.float32)\n",
    "        input_ts = preprocess_input(input_ts)\n",
    "        input_ts = tf.convert_to_tensor(input_ts,tf.float32)\n",
    "\n",
    "        label_tr = tf.convert_to_tensor(label_tr,tf.float32)\n",
    "        label_ts = tf.convert_to_tensor(label_ts,tf.float32)\n",
    "        inp = (input_tr, input_ts, label_tr, label_ts)\n",
    "        result = outer_eval_step(inp, model, meta_batch_size=batch_size, num_inner_updates=num_inner_updates)\n",
    "        val_post_accs.append(result[-1][-1])\n",
    "        print('Meta-validation pre-inner-loop train accuracy: %.5f, meta-validation post-inner-loop test accuracy: %.5f' % (result[-2], result[-1][-1]))\n",
    "    # return post_accuracies\n",
    "#   model_file = '.' + '/' +'model' + str(itr)\n",
    "#   print(\"Saving to \", model_file)\n",
    "#   model.save_weights(model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<tf.Tensor: id=3542454, shape=(), dtype=float32, numpy=1.02407665e-08>]"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "result[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.test.is_gpu_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
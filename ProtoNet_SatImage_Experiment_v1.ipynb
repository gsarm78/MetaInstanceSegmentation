{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProtoNet_SatImage_Experiment_v1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMfFfYkkh3CECBzX521KU/N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gsarm78/MetaSegmentation/blob/main/ProtoNet_SatImage_Experiment_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTzqy7iWBpcV",
        "outputId": "8c63f819-f609-4e39-f05f-1a0b22fe72fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LofY-WeEBrlX"
      },
      "source": [
        "# Data are renamed with a numbered filename\n",
        "!unzip /content/drive/My\\ Drive/cs330Data/data.zip -d /content/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRBuZ4-iB2RV",
        "outputId": "9ea577ae-6d63-47c6-89ea-21ac358a4ace",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rm -r /content/data/__MACOSX"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/content/data/__MACOSX': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-MfvXltK0S4"
      },
      "source": [
        "!unzip /content/drive/My\\ Drive/cs330Data/data2.zip -d /content/data2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKrEfGteK42n"
      },
      "source": [
        "rm -r /content/data2/__MACOSX"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ikrHGH9MM8j"
      },
      "source": [
        "Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46gn6-EqCh0L",
        "outputId": "6fc63a97-6eff-489b-d092-f43d84c42f69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/gsarm78/MetaSegmentation.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MetaSegmentation'...\n",
            "remote: Enumerating objects: 40, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 40 (delta 15), reused 6 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (40/40), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndbfu9iECpr0"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFvNdoW5DLIN"
      },
      "source": [
        "pano_directory = '/content/data/data/train'\n",
        "labels_directory = '/content/data/data/labels'\n",
        "dataset_csv = '/content/MetaSegmentation/andrew_fewshot_dataloader/dataset_10_31_2020_3903_clustered.csv'\n",
        "df = pd.read_csv('/content/MetaSegmentation/andrew_fewshot_dataloader/dataset_10_31_2020_3903_clustered.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y363H4kzDPws"
      },
      "source": [
        "def get_image(path,IMG_WIDTH=255,IMG_HEIGHT=255,IMG_CHANNELS=3):\n",
        "    '''\n",
        "    '''\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((IMG_WIDTH,IMG_HEIGHT))\n",
        "    return img\n",
        "\n",
        "def get_mask(path,IMG_WIDTH=255,IMG_HEIGHT=255):\n",
        "    '''\n",
        "    '''\n",
        "    img = Image.open(path)\n",
        "    img = img.resize((IMG_WIDTH,IMG_HEIGHT))\n",
        "    img = np.array(img)/255.\n",
        "    img = np.expand_dims(img[:,:,0],axis=-1)\n",
        "\n",
        "    return img\n",
        "def get_images(dataset,n_samples=16,shuffle=True):\n",
        "    '''\n",
        "    '''\n",
        "    set = random.sample(dataset,n_samples)\n",
        "    return set"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdXj83iaDSRv"
      },
      "source": [
        "class DataGenerator(object):\n",
        "    def __init__(self,\n",
        "                 dataset_csv,\n",
        "                 pano_directory,\n",
        "                 label_directory,\n",
        "                 num_classes,\n",
        "                 num_samples_per_class,\n",
        "                 num_meta_test_classes,\n",
        "                 num_meta_test_samples_per_class,\n",
        "                 IMG_WIDTH=255,\n",
        "                 IMG_HEIGHT=255,\n",
        "                 num_circles=3):\n",
        "        '''\n",
        "        '''\n",
        "        self.num_samples_per_class = num_samples_per_class\n",
        "        self.num_classes = num_classes\n",
        "        self.num_meta_test_samples_per_class = num_meta_test_samples_per_class\n",
        "        self.num_meta_test_classes = num_meta_test_classes\n",
        "        self.dataset_csv = dataset_csv\n",
        "        self.num_circles=num_circles\n",
        "        self.dataset_df = pd.read_csv(self.dataset_csv)\n",
        "        # limit the dataset to only contain examples with N num_circles\n",
        "        self.dataset_df = df[df['num_circles']==self.num_circles-1]# zero index\n",
        "        self.pano_directory = pano_directory\n",
        "        self.label_directory = label_directory\n",
        "        \n",
        "        self.IMG_WIDTH=IMG_WIDTH\n",
        "        self.IMG_HEIGHT=IMG_HEIGHT\n",
        "        data_ids = [os.path.join(pano_directory,i) for i in df['pano_name'].tolist()]\n",
        "        label_ids =  [os.path.join(labels_directory,i) for i in df['label_name'].tolist()]\n",
        "        self.dataset = list(zip(data_ids,label_ids))\n",
        "\n",
        "        self.NUM = len(self.dataset)\n",
        "        self.train_split = 0.8\n",
        "        self.val_split = 0.1\n",
        "        self.test_split = 0.1\n",
        "\n",
        "        self.num_train = int(self.train_split*self.NUM)\n",
        "        self.num_val = int(self.val_split*self.NUM)\n",
        "        self.num_test = int(self.test_split*self.NUM)\n",
        "        # print(NUM,num_train,num_val,num_test)\n",
        "        random.seed(123)\n",
        "        random.shuffle(self.dataset)\n",
        "        self.train_dataset = self.dataset[:self.num_train]\n",
        "        self.val_dataset = self.dataset[self.num_train:self.num_train+self.num_val]\n",
        "        self.test_dataset = self.dataset[self.num_train+self.num_val+1:]\n",
        "\n",
        "    def sample_batch(self,batch_type,batch_size,shuffle=True,swap=False):\n",
        "        if batch_type =='meta_train':\n",
        "            folders = self.train_dataset\n",
        "            num_classes = self.num_classes\n",
        "            num_samples_per_class = self.num_samples_per_class\n",
        "        elif batch_type == 'meta_val':\n",
        "            folders = self.val_dataset\n",
        "            num_classes = self.num_classes\n",
        "            num_samples_per_class = self.num_samples_per_class\n",
        "        else:\n",
        "            folders = self.test_dataset\n",
        "            num_classes = self.num_meta_test_classes\n",
        "            num_samples_per_class = self.num_meta_test_samples_per_class\n",
        "\n",
        "        all_image_batches = []\n",
        "        all_label_batches = []\n",
        "        for i in range(batch_size):\n",
        "            # dont need to random sample folders, since only one class\n",
        "            labels_and_images = get_images(folders,n_samples=num_samples_per_class)\n",
        "            labels = [get_mask(li[1]) for li in labels_and_images]\n",
        "            images = [get_image(li[0]) for li in labels_and_images]\n",
        "\n",
        "            labels = np.stack(labels).astype(np.int32)\n",
        "            labels = np.reshape(labels,(num_classes,\n",
        "                                        num_samples_per_class,\n",
        "                                        self.IMG_WIDTH,\n",
        "                                        self.IMG_HEIGHT,\n",
        "                                        -1))\n",
        "            images = np.stack(images)\n",
        "            images = np.reshape(images,(num_classes,\n",
        "                                        num_samples_per_class,\n",
        "                                        self.IMG_WIDTH,\n",
        "                                        self.IMG_HEIGHT,\n",
        "                                        -1))\n",
        "            print(labels.shape,images.shape)\n",
        "            all_image_batches.append(images)\n",
        "            all_label_batches.append(labels)\n",
        "        all_image_batches = np.stack(all_image_batches)\n",
        "        all_label_batches = np.stack(all_label_batches)\n",
        "        print(all_image_batches.shape,all_label_batches.shape)\n",
        "        return all_image_batches,all_label_batches"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbArKUy5DV4N",
        "outputId": "c930cb7f-e1a6-4639-a3bd-e297945e356b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "d = DataGenerator(dataset_csv=dataset_csv,\n",
        "                 pano_directory=pano_directory,\n",
        "                 label_directory=labels_directory,\n",
        "                 num_classes=1,\n",
        "                 num_samples_per_class=2*2,#2-shot\n",
        "                 num_meta_test_classes=1,\n",
        "                 num_meta_test_samples_per_class=3*2,#3-shot test\n",
        "                 IMG_WIDTH=255,\n",
        "                 IMG_HEIGHT=255,\n",
        "                 num_circles=3)\n",
        "batch_size = 4\n",
        "batch_type = 'meta_val'\n",
        "images, labels = d.sample_batch(batch_type,batch_size)\n",
        "print(images.shape,labels.shape)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 4, 255, 255, 1) (1, 4, 255, 255, 4)\n",
            "(1, 4, 255, 255, 1) (1, 4, 255, 255, 4)\n",
            "(1, 4, 255, 255, 1) (1, 4, 255, 255, 4)\n",
            "(1, 4, 255, 255, 1) (1, 4, 255, 255, 4)\n",
            "(4, 1, 4, 255, 255, 4) (4, 1, 4, 255, 255, 1)\n",
            "(4, 1, 4, 255, 255, 4) (4, 1, 4, 255, 255, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-_CQI__bXwU"
      },
      "source": [
        "#ProtoNet\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "class ProtoNet(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, num_filters, latent_dim):\n",
        "    super(ProtoNet, self).__init__()\n",
        "    self.num_filters = num_filters\n",
        "    self.latent_dim = latent_dim\n",
        "    num_filter_list = self.num_filters + [latent_dim]\n",
        "    self.convs = []\n",
        "    for i, num_filter in enumerate(num_filter_list):\n",
        "      block_parts = [\n",
        "        layers.Conv2D(\n",
        "          filters=num_filter,\n",
        "          kernel_size=3,\n",
        "          padding='SAME',\n",
        "          activation='linear'),\n",
        "      ]\n",
        "\n",
        "      block_parts += [layers.BatchNormalization()]\n",
        "      block_parts += [layers.Activation('relu')]\n",
        "      block_parts += [layers.MaxPool2D()]\n",
        "      block = tf.keras.Sequential(block_parts, name='conv_block_%d' % i)\n",
        "      self.__setattr__(\"conv%d\" % i, block)\n",
        "      self.convs.append(block)\n",
        "    self.flatten = tf.keras.layers.Flatten()\n",
        "\n",
        "  def call(self, inp):\n",
        "    out = inp\n",
        "    for conv in self.convs:\n",
        "      out = conv(out)\n",
        "    out = self.flatten(out)\n",
        "    return out\n",
        "\n",
        "def ProtoLoss(x_latent, q_latent, labels_onehot, num_classes, num_support, num_queries):\n",
        "  \"\"\"\n",
        "    calculates the prototype network loss using the latent representation of x\n",
        "    and the latent representation of the query set\n",
        "    Args:\n",
        "      x_latent: latent representation of supports with shape [N*S, D], where D is the latent dimension\n",
        "      q_latent: latent representation of queries with shape [N*Q, D], where D is the latent dimension\n",
        "      labels_onehot: one-hot encodings of the labels of the queries with shape [N, Q, N]\n",
        "      num_classes: number of classes (N) for classification\n",
        "      num_support: number of examples (S) in the support set\n",
        "      num_queries: number of examples (Q) in the query set\n",
        "    Returns:\n",
        "      ce_loss: the cross entropy loss between the predicted labels and true labels\n",
        "      acc: the accuracy of classification on the queries\n",
        "  \"\"\"\n",
        "  q_labels = labels_onehot[:, :, -num_queries:]\n",
        "  q_labels = tf.reshape(q_labels, (num_classes*num_queries, -1))\n",
        "  q_latent = tf.reshape(q_latent, (num_classes*num_queries, 1, -1))\n",
        "  q_latent = tf.tile(q_latent, (1, num_classes, 1))\n",
        "  x_latent = tf.reshape(x_latent, (num_classes, num_support, -1))\n",
        "\n",
        "  ck = tf.reduce_mean(x_latent, axis=1)\n",
        "  centroids = tf.reshape(ck, (1, num_classes, -1))\n",
        "  centroids = tf.tile(centroids, (num_classes*num_queries,1,1))\n",
        "  # compute the distance from the prototypes\n",
        "  distances = -tf.norm(q_latent - centroids, axis=-1)  #default to Euclidean distance (ord='euclidean')\n",
        "  # compute cross entropy loss\n",
        "  computed_ce_loss = tf.nn.softmax_cross_entropy_with_logits(labels=q_labels, logits=distances)\n",
        "  #return the cross-entropy loss \n",
        "  ce_loss = tf.reduce_mean(computed_ce_loss)\n",
        "  #return accuracy\n",
        "  acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(q_labels, axis=-1), tf.argmax(distances, axis=-1)), dtype=tf.float32))\n",
        "  return ce_loss, acc"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQMWeoKebYEA"
      },
      "source": [
        "# run_ProtoNet\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def proto_net_train_step(model, optim, x, q, labels_ph):\n",
        "  num_classes, num_support, im_height, im_width, channels = x.shape\n",
        "  num_queries = q.shape[1]\n",
        "  x = tf.reshape(x, [-1, im_height, im_width, channels])\n",
        "  q = tf.reshape(q, [-1, im_height, im_width, channels])\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    x_latent = model(x)\n",
        "    q_latent = model(q)\n",
        "    ce_loss, acc = ProtoLoss(x_latent, q_latent, labels_ph, num_classes, num_support, num_queries)\n",
        "\n",
        "  gradients = tape.gradient(ce_loss, model.trainable_variables)\n",
        "  optim.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "  return ce_loss, acc\n",
        "\n",
        "def proto_net_eval(model, x, q, labels_ph):\n",
        "  num_classes, num_support, im_height, im_width, channels = x.shape\n",
        "  num_queries = q.shape[1]\n",
        "  x = tf.reshape(x, [-1, im_height, im_width, channels])\n",
        "  q = tf.reshape(q, [-1, im_height, im_width, channels])\n",
        "\n",
        "  x_latent = model(x)\n",
        "  q_latent = model(q)\n",
        "  ce_loss, acc = ProtoLoss(x_latent, q_latent, labels_ph, num_classes, num_support, num_queries)\n",
        "\n",
        "  return ce_loss, acc \n",
        "\n",
        "def run_protonet(n_way=1, k_shot=2, n_query=2, n_meta_test_way=1, k_meta_test_shot=3, n_meta_test_query=3):\n",
        "  n_epochs = 20\n",
        "  n_episodes = 100\n",
        "\n",
        "  im_width, im_height, channels = 255, 255, 3\n",
        "  num_filters = 32\n",
        "  latent_dim = 16\n",
        "  num_conv_layers = 3\n",
        "  n_meta_test_episodes = 1000\n",
        "\n",
        "  model = ProtoNet([num_filters]*num_conv_layers, latent_dim)\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "  writer = tf.summary.create_file_writer(f'/content/logs/')\n",
        "\n",
        "  with writer.as_default():\n",
        "    # call DataGenerator with k_shot+n_query samples per class\n",
        "    data_generator = DataGenerator(dataset_csv=dataset_csv,\n",
        "                                   pano_directory=pano_directory,\n",
        "                                   label_directory=labels_directory,\n",
        "                                   num_classes=n_way, \n",
        "                                   num_samples_per_class=k_shot+n_query, \n",
        "                                   num_meta_test_classes=n_meta_test_way, \n",
        "                                   num_meta_test_samples_per_class=k_meta_test_shot+n_meta_test_query,\n",
        "                                   IMG_WIDTH=255, IMG_HEIGHT=255, num_circles=3)\n",
        "    for ep in range(n_epochs):\n",
        "      for epi in range(n_episodes):\n",
        "        # sample a batch of training data and partition it into\n",
        "        # support and query sets\n",
        "\n",
        "        images, labels = data_generator.sample_batch(batch_type='meta_train', batch_size=4, shuffle=False, swap=False) \n",
        "        \n",
        "        #images = images.reshape(n_way, k_shot+n_query, im_width, im_height, channels)\n",
        "\n",
        "        support = images[:,:k_shot]\n",
        "        query = images[:,-n_query:]\n",
        "\n",
        "        ls, ac = proto_net_train_step(model, optimizer, x=support, q=query, labels_ph=labels)\n",
        "        if (epi+1) % 50 == 0:\n",
        "          #############################\n",
        "          # sample a batch of validation data and partition it into\n",
        "          # support and query sets\n",
        "          images, labels = data_generator.sample_batch(batch_type='meta_val', batch_size=4, shuffle=False, swap=False)\n",
        "          images = images.reshape(n_way, k_shot + n_query, im_width, im_height, channels)\n",
        "          support = images[:,:k_shot]\n",
        "          query = images[:,-n_query:]\n",
        "          #############################\n",
        "          val_ls, val_ac = proto_net_eval(model, x=support, q=query, labels_ph=labels)\n",
        "          print('[epoch {}/{}, episode {}/{}] => meta-training loss: {:.5f}, meta-training acc: {:.5f}, meta-val loss: {:.5f}, meta-val acc: {:.5f}'.format(ep+1,\n",
        "                                                                      n_epochs,\n",
        "                                                                      epi+1,\n",
        "                                                                      n_episodes,\n",
        "                                                                      ls,\n",
        "                                                                      ac,\n",
        "                                                                      val_ls,\n",
        "                                                                      val_ac))\n",
        "          ## Adding Logging\n",
        "          tf.summary.scalar('Validation Loss', val_ls, step=ep*n_episodes+epi)\n",
        "          tf.summary.scalar('Validation Accuracy', val_ac, step=ep*n_episodes+epi)\n",
        "          writer.flush()\n",
        "\n",
        "  print('Testing...')\n",
        "  meta_test_accuracies = []\n",
        "  for epi in range(n_meta_test_episodes):\n",
        "\n",
        "    # sample a batch of test data and partition it into\n",
        "    # support and query sets\n",
        "    images, labels = data_generator.sample_batch(batch_type='meta_test', batch_size=1, shuffle=False,swap=False)\n",
        "    images = images.reshape(n_way, k_meta_test_shot + n_meta_test_query, im_width, im_height, channels)\n",
        "    support = images[:,:k_meta_test_shot]\n",
        "    query = images[:,-n_meta_test_query:]\n",
        "\n",
        "    ls, ac = proto_net_eval(model, x=support, q=query, labels_ph=labels)\n",
        "    meta_test_accuracies.append(ac)\n",
        "    if (epi+1) % 50 == 0:\n",
        "      print('[meta-test episode {}/{}] => loss: {:.5f}, acc: {:.5f}'.format(epi+1, n_meta_test_episodes, ls, ac))\n",
        "  avg_acc = np.mean(meta_test_accuracies)\n",
        "  stds = np.std(meta_test_accuracies)\n",
        "  print('Average Meta-Test Accuracy: {:.5f}, Meta-Test Accuracy Std: {:.5f}'.format(avg_acc, stds))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVPwNTtgbYMF",
        "outputId": "18562bd6-9d43-430f-e490-502f56c303ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        }
      },
      "source": [
        "run_protonet(n_way=1, k_shot=2, n_query=2, n_meta_test_way=1, k_meta_test_shot=3, n_meta_test_query=3)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 4, 255, 255, 1) (1, 4, 255, 255, 4)\n",
            "(1, 4, 255, 255, 1) (1, 4, 255, 255, 4)\n",
            "(1, 4, 255, 255, 1) (1, 4, 255, 255, 4)\n",
            "(1, 4, 255, 255, 1) (1, 4, 255, 255, 4)\n",
            "(4, 1, 4, 255, 255, 4) (4, 1, 4, 255, 255, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-46e1dc3291d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_protonet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_way\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_query\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_meta_test_way\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_meta_test_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_meta_test_query\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-52-957720773ab4>\u001b[0m in \u001b[0;36mrun_protonet\u001b[0;34m(n_way, k_shot, n_query, n_meta_test_way, k_meta_test_shot, n_meta_test_query)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mn_query\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproto_net_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msupport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_ph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m           \u001b[0;31m#############################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-957720773ab4>\u001b[0m in \u001b[0;36mproto_net_train_step\u001b[0;34m(model, optim, x, q, labels_ph)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mproto_net_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_ph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_support\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mnum_queries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 5)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiD6NAOCnInl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}